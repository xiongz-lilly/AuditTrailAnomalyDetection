{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "952ccd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sentence1 = \\'I like apples\\'\\nsentence2 = \\'You like oranages\\'\\nwordlist1 = sentence1.rsplit()\\nwordlist2 = sentence2.rsplit()\\nprint(wordlist1)\\nprint(wordlist2)\\n\\nfor word in wordlist1:\\n    if word in sentence2:\\n        print(word, \\'found\\', \"in\", sentence2)\\n        \\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''sentence1 = 'I like apples'\n",
    "sentence2 = 'You like oranages'\n",
    "wordlist1 = sentence1.rsplit()\n",
    "wordlist2 = sentence2.rsplit()\n",
    "print(wordlist1)\n",
    "print(wordlist2)\n",
    "\n",
    "for word in wordlist1:\n",
    "    if word in sentence2:\n",
    "        print(word, 'found', \"in\", sentence2)\n",
    "        \n",
    "'''   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0df1625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac171d01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aea9f851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df_PLC_ServiceNow= pd.read_excel(\n",
    "     os.path.join(\"PLC Download version 2.xlsx\"),\n",
    "     engine='openpyxl',\n",
    ")\n",
    "\n",
    "#print(df_PLC_ServiceNow)\n",
    "#print(df_PLC_ServiceNow['Change Implementer'][0])\n",
    "#print(df_PLC_ServiceNow['Deployment Actual Start Date'][3])\n",
    "#print(df_PLC_ServiceNow['Deployment Actual Start Date'][0])\n",
    "\n",
    "\n",
    "nrows_PLC_ServiceNow = df_PLC_ServiceNow.shape[0]\n",
    "print(nrows_PLC_ServiceNow)\n",
    "\n",
    "dataFrame1 = pd.DataFrame(columns = ['System ID', 'start_time', 'end_time', 'Notes'])\n",
    "\n",
    "for i in range(nrows_PLC_ServiceNow):\n",
    "    strg = df_PLC_ServiceNow['Change Implementer'][i] # extract ID from 'assigned to'\n",
    "    #print('strg type is:', type(strg))\n",
    "    #pos = strg.find('(')\n",
    "    #df_PLC_ServiceNow['assigned_to'][i] = strg[pos+1:-1]\n",
    "    # dataFrame1.loc[i, 'System ID'] = strg[pos+1:-1]\n",
    "    if( not (pd.isna(strg))):\n",
    "        dataFrame1.loc[i, 'System ID'] = strg\n",
    "    #print(dataFrame1)\n",
    "    \n",
    "    #print(df_PLC_ServiceNow['work_start'][i])\n",
    "    #print(df_PLC_ServiceNow['work_end'][i])\n",
    "    \n",
    "    #dataFrame1.loc[i, 'start_time'] = convert_timestring_to_seconds(df_PLC_ServiceNow['Deployment Actual Start Date'][i])\n",
    "    #dataFrame1.loc[i, 'end_time'] = convert_timestring_to_seconds(df_PLC_ServiceNow['Deployment Actual End Date'][i])\n",
    "    \n",
    "    datetimeObj = df_PLC_ServiceNow['Deployment Actual Start Date'][i]\n",
    "    #print('type(datetimeObj):', type(datetimeObj))\n",
    "    #print('datetimeObj:', datetimeObj)\n",
    "    if( not (pd.isna(datetimeObj))):\n",
    "        dataFrame1.loc[i, 'start_time'] = datetimeObj.timestamp()\n",
    "    else:\n",
    "        dataFrame1.loc[i, 'start_time'] = 0.0\n",
    "    #print('PLC: Unix_time is:', dataFrame1.loc[i, 'start_time'] )    \n",
    "        \n",
    "        \n",
    "    datetimeObj = df_PLC_ServiceNow['Deployment Actual End Date'][i]\n",
    "    if( not (pd.isna(datetimeObj))):\n",
    "        dataFrame1.loc[i, 'end_time'] = datetimeObj.timestamp()\n",
    "    else:\n",
    "        dataFrame1.loc[i, 'end_time'] = 0.0\n",
    "        \n",
    "    dataFrame1.loc[i, 'Notes'] = df_PLC_ServiceNow['Deployment Execution Notes'][i]    \n",
    "   \n",
    "#print(dataFrame1.iloc[6, :]) \n",
    "#print(dataFrame1.iloc[9, :]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ead6d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def convert_timestring_to_seconds(time_string):\n",
    "    \"\"\"Convert time_string to Unix time: timestamp()\"\"\"\n",
    "    \n",
    "    '''It turns out the time format the *.csv file is all \"dd-mm-yyyy hh:mm\" format'''\n",
    "    \n",
    "    # Using datetime.strptime()\n",
    "    if time_string.find('/') != -1:\n",
    "        print('find slash character')\n",
    "        dt = datetime.strptime(time_string, \"%m/%d/%Y %H:%M\")\n",
    "    else: # dd-mm-yyyy H:M\n",
    "        '''time_string = time_string.replace('-', '/')\n",
    "        print('time_string:', time_string)\n",
    "        loc1 = time_string.find('/')\n",
    "        loc2 = time_string.rfind('/')\n",
    "        dd = time_string[0:loc1]\n",
    "        print('dd', dd)\n",
    "        mm = time_string[loc1+1:loc2]\n",
    "        print('mm:', mm)\n",
    "        result_string = mm +'/'+ dd +time_string[loc2:]\n",
    "        print('result_string:', result_string)\n",
    "        dt = datetime.strptime(result_string, \"%m/%d/%Y %H:%M\")'''\n",
    "        \n",
    "        dt = datetime.strptime(time_string, \"%m-%d-%Y %H:%M\") # Note: Y upper case is necessary\n",
    "    \n",
    "    Unix_time = dt.timestamp()\n",
    "    return Unix_time\n",
    "\n",
    "def convert_TwoTimeFields_to_seconds(date_field, hhmmss_am_or_pm_string):\n",
    "    \"\"\"Convert time_string to Unix time: timestamp()\"\"\"\n",
    "    \n",
    "    #print('type(hhmmss_am_or_pm_string):', type(hhmmss_am_or_pm_string))\n",
    "    #print(date_field + hhmmss_am_or_pm_string)\n",
    "    \n",
    "    date_string = date_field.strftime('%Y-%m-%d') # convert from timestamp format to str \n",
    "    #datetimeObj = datetime.strptime(date_string +' '+ hhmmss_am_or_pm_string, \"%Y-%m-%d %I:%M:%S %p\") # I, not H\n",
    "    #print('type(date_field):', type(datetimeObj))\n",
    "    #print(datetimeObj)    \n",
    "    #Unix_time = datetimeObj.timestamp()\n",
    "    \n",
    "    ts = pd.Timestamp(date_string +' '+ hhmmss_am_or_pm_string)\n",
    "    Unix_time = ts.timestamp()\n",
    "    #print('AuditTrail: Unix_time is:', Unix_time)\n",
    "    return Unix_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e235210c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "df_PLC_AuditTrail= pd.read_excel(\n",
    "     os.path.join(\"Example_AuditTrail_PLC_ByZiyou.xlsx\"),\n",
    "     engine='openpyxl',\n",
    ")\n",
    "\n",
    "#print(df_PLC_AuditTrail)\n",
    "\n",
    "#print(df_PLC_AuditTrail['Username'])\n",
    "#print(df_PLC_AuditTrail['Occurred'])\n",
    "#print(df_PLC_AuditTrail['Time'])\n",
    "\n",
    "# extract ID from 'assigned to'\n",
    "nrows_PLC_AuditTrail = df_PLC_AuditTrail.shape[0]\n",
    "print(nrows_PLC_AuditTrail)\n",
    "\n",
    "dataFrame2 = pd.DataFrame(columns = ['System ID', 'Time', 'Notes'])\n",
    "\n",
    "for i in range(nrows_PLC_AuditTrail):\n",
    "    strg = df_PLC_AuditTrail['Username'][i]\n",
    "    #print('strg:', strg)\n",
    "    pos = strg.find('\\\\')\n",
    "    #df_PLC_ServiceNow['assigned_to'][i] = strg[pos+1:-1]\n",
    "    dataFrame2.loc[i, 'System ID'] = strg[pos+1:]\n",
    "    #print(df_PLC_AuditTrail['Occurred'][i])\n",
    "    #print(df_PLC_AuditTrail['Time'][i])                    \n",
    "        \n",
    "    dataFrame2.loc[i, 'Time'] = convert_TwoTimeFields_to_seconds(df_PLC_AuditTrail['Occurred'][i], df_PLC_AuditTrail['Time'][i])\n",
    "    \n",
    "    dataFrame2.loc[i, 'Notes'] = df_PLC_AuditTrail['Message'][i]\n",
    "\n",
    "#dataFrame2       \n",
    "#dataFrame2.iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46244231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foundMatch(record01, record02, durationAllowed=3600): # 1800 seconds\n",
    "    ID01 = record01['System ID']\n",
    "    time01_1 = record01['start_time']\n",
    "    time01_2 = record01['end_time']\n",
    "    time01 = (time01_1 + time01_2)/2\n",
    "    \n",
    "    ID02 = record02['System ID']\n",
    "    time02 = record02['Time']\n",
    "    \n",
    "    \n",
    "    match = 0\n",
    "    if((not pd.isna(ID01)) and (not pd.isna(ID02))):\n",
    "        if (((ID01 in ID02) or (ID02 in ID01)) and abs((abs(time01-time02)))<durationAllowed): #14400: 4 days, ToDO\n",
    "            print(\"tim01 - time02 = \", abs(time01 - time02), 'sec')\n",
    "            match = 1;\n",
    "        \n",
    "    return match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "686f2042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tim01 - time02 =  18.5 sec\n",
      "ServiceNow record: 6\n",
      "Sean Passino (C265783) \t 2021-08-26 08:01:20 \t 2021-08-26 08:01:23\n",
      "AuditTrail record: 53\n",
      " AM\\C265783 \t 2021-08-26 \t  8:01:03 AM\n",
      "match.\n",
      "----------------------------------------------------------\n",
      "tim01 - time02 =  2562.5 sec\n",
      "ServiceNow record: 9\n",
      "Sean Passino (C265783) \t 2021-08-31 19:10:10 \t 2021-08-31 19:10:13\n",
      "AuditTrail record: 54\n",
      " AM\\C265783 \t 2021-08-31 \t  6:27:29 PM\n",
      "match.\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# compare the two dataFrames\n",
    "for i in range(nrows_PLC_ServiceNow):\n",
    "    row_PLC_ServiceNow = dataFrame1.iloc[i, :]\n",
    "    #print(row_PLC_ServiceNow)\n",
    "    for j in range(nrows_PLC_AuditTrail):        \n",
    "        row_PLC_AuditTrail = dataFrame2.iloc[j, :]\n",
    "        #print(row_PLC_AuditTrail)\n",
    "        \n",
    "        # average the two timestamps in AuditTrail\n",
    "        #if i == 6 and j == 53:\n",
    "        #    print(row_PLC_ServiceNow)\n",
    "        #    print(row_PLC_AuditTrail)\n",
    "        match = foundMatch(row_PLC_ServiceNow, row_PLC_AuditTrail)\n",
    "        \n",
    "        if match == 1: # and i == 6 and j == 53:\n",
    "            print('ServiceNow record:', i)\n",
    "            print(df_PLC_ServiceNow['Change Implementer'][i], '\\t', df_PLC_ServiceNow['Deployment Actual Start Date'][i], '\\t', df_PLC_ServiceNow['Deployment Actual End Date'][i])\n",
    "            print('AuditTrail record:', j)\n",
    "            data_field = df_PLC_AuditTrail['Occurred'][j]\n",
    "            print(df_PLC_AuditTrail['Username'][j], '\\t', data_field.strftime('%Y-%m-%d'), '\\t', df_PLC_AuditTrail['Time'][j])\n",
    "            print('match.')\n",
    "            print('----------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e50e330",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import itertools\n",
    "import spacy\n",
    "\n",
    "\n",
    "# function to remove punctuation from text (input is a string)\n",
    "def clean_text(sentence):\n",
    "    clean_sentence = \"\".join(l for l in sentence if l not in string.punctuation)\n",
    "\n",
    "    return clean_sentence\n",
    "\n",
    "\n",
    "# function to calculate the cosine\n",
    "def cosine_similarity_calc(vec_1, vec_2):\n",
    "    sim = np.dot(vec_1, vec_2) / (np.linalg.norm(vec_1) * np.linalg.norm(vec_2))\n",
    "\n",
    "    return sim\n",
    "\n",
    "# load word embeddings (will use these to convert sentence to vectors)\n",
    "    # Note you will need to run the following command (from cmd) to download embeddings:\n",
    "    # 'python -m spacy download en_core_web_lg'\n",
    "    embeddings = spacy.load('en_core_web_lg')\n",
    "\n",
    "# function to calculate cosine similarity using word vectors (input is a series)\n",
    "def embeddings_similarity(sentences):\n",
    "    # first we need to get data into | sentence_a | sentence_b | format\n",
    "    sentence_pairs = list(itertools.combinations(sentences, 2))\n",
    "\n",
    "    sentence_a = [pair[0] for pair in sentence_pairs]\n",
    "    sentence_b = [pair[1] for pair in sentence_pairs]\n",
    "\n",
    "    sentence_pairs_df = pd.DataFrame({'sentence_a': sentence_a, 'sentence_b': sentence_b})\n",
    "\n",
    "    # get unique combinations of sentance_a and sentance_b\n",
    "    sentence_pairs_df = sentence_pairs_df.loc[pd.DataFrame(np.sort(sentence_pairs_df[['sentence_a', 'sentence_b']], 1)\n",
    "                                                           , index=sentence_pairs_df.index).drop_duplicates(\n",
    "        keep='first').index]\n",
    "\n",
    "    # remove instances where sentence a == sentence b\n",
    "    sentence_pairs_df = sentence_pairs_df[sentence_pairs_df['sentence_a'] != sentence_pairs_df['sentence_b']]\n",
    "\n",
    "    \n",
    "\n",
    "    # now we are ready to calculate the similarity\n",
    "\n",
    "    sentence_pairs_df['similarity'] = sentence_pairs_df.apply(\n",
    "        lambda row: cosine_similarity_calc(embeddings(clean_text(row['sentence_a'])).vector,\n",
    "                                           embeddings(clean_text(row['sentence_b'])).vector), axis=1)\n",
    "\n",
    "    return sentence_pairs_df\n",
    "\n",
    "\n",
    "# function to calculate cosine similarity using word vectors (input is a series)\n",
    "\n",
    "#nlp = spacy.load(\"en_core_web_md\") \n",
    "nlp = spacy.load(\"en_core_web_lg\") \n",
    "\n",
    "def doc_similarity(sentence1, sentence2): # reference: https://spacy.io/usage/spacy-101\n",
    "    doc1 = nlp(sentence1)\n",
    "    doc2 = nlp(sentence2)\n",
    "    \n",
    "    score = doc1.similarity(doc2)\n",
    "    \n",
    "    return score\n",
    "\n",
    "# Remove Special Characters from a String Using re.sub()\n",
    "import re\n",
    "def sentence_similarity_ziyou(sentence1, sentence2): # reference: https://spacy.io/usage/spacy-101\n",
    "    \n",
    "    sentence1 = sentence1.lower()\n",
    "    sentence2 = sentence2.lower()\n",
    "    \n",
    "    sentence1 = re.sub(r\"[^a-zA-Z0-9 ]\", \"\", sentence1)\n",
    "    sentence2 = re.sub(r\"[^a-zA-Z0-9 ]\", \"\", sentence2)\n",
    "    \n",
    "    wordlist1 = sentence1.rsplit()\n",
    "    wordlist2 = sentence2.rsplit()\n",
    "    \n",
    "    #print(wordlist1)\n",
    "    #print(wordlist2)\n",
    "    \n",
    "    len01 = len(wordlist1)\n",
    "    len02 = len(wordlist2)\n",
    "    \n",
    "    if(len01 < len02):\n",
    "        longlist = wordlist2\n",
    "        shortlist = wordlist1\n",
    "        long_sentence = sentence2\n",
    "    else:\n",
    "        longlist = wordlist1\n",
    "        shortlist = wordlist2\n",
    "        long_sentence = sentence1\n",
    "    \n",
    "    len_shortlist = len(shortlist)\n",
    "    \n",
    "    wordFound = 0\n",
    "    for word in shortlist:\n",
    "        if word in longlist:\n",
    "            #print('found word:', word)\n",
    "            wordFound = wordFound + 1\n",
    "    if len_shortlist == 0:\n",
    "        ratio_wordsFound = 0.0\n",
    "    else: \n",
    "        ratio_wordsFound = wordFound / len_shortlist\n",
    "        \n",
    "    two_words_found = 0\n",
    "    for i in range(0, len_shortlist-1): # note [-1] means not using the last one\n",
    "        two_words = shortlist[i] + ' ' + shortlist[i+1]\n",
    "        if long_sentence.find(two_words) != -1:\n",
    "            two_words_found = two_words_found + 1\n",
    "        \n",
    "        \n",
    "    if len_shortlist == 0:    \n",
    "        ratio_two_words_Found = 0.0\n",
    "    else: \n",
    "        ratio_two_words_Found = two_words_found / len_shortlist\n",
    "        \n",
    "        \n",
    "    return [ratio_wordsFound, ratio_two_words_Found]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc870d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "s1 = 'Changed Data Bit Value of Tag [ \\PUPSIT.Ready_to_Fill ] to [ 1 ]'\n",
    "s2 = 'The value of the PUPSIT.Ready_To_Fill bit was changed from a 0 to a 1. Immediately after doing this, Operations was able to restart the machine without re-performing the PUPSIT process.'\n",
    "print(sentence_similarity_ziyou(s1, s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89b47a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i =  0\n",
      "i =  1\n",
      "i =  2\n",
      "i =  3\n",
      "i =  4\n",
      "i =  5\n",
      "i =  6\n",
      "i =  6 max_j_idx =  53 max_score =  0.7777777777777778 matching sentences are: The value of the PUPSIT.Ready_To_Fill bit was changed from a 0 to a 1. Immediately after doing this, Operations was able to restart the machine without re-performing the PUPSIT process. \n",
      "----------------\n",
      "  Changed Data Bit Value of Tag [ \\PUPSIT.Ready_to_Fill ] to [ 1 ]\n",
      "i =  7\n",
      "i =  8\n",
      "i =  9\n",
      "i =  9 max_j_idx =  54 max_score =  0.8 matching sentences are: The value of tag IIN.DINT_SequenceProductionStartUp from 31 to 20. Scale Verification mode was successfully enabled \n",
      "----------------\n",
      "  Changed Data Value of Tag [ \\IIN.DINT_SequenceProductionStartUp ] from [ 31 ] to [ 20 ]\n",
      "i =  10\n",
      "i =  11\n",
      "i =  12\n",
      "i =  13\n",
      "i =  14\n",
      "i =  14 max_j_idx =  4 max_score =  0.7777777777777778 matching sentences are: On 16Aug2021at approx. 11:55, PLC tag AE2700A05.Data_Flt.Alarm was toggled (set to 0) by Assoc. Consultant Engineer -Automation Matthew Kishe. The changed the value from 1 to 0. This caused the HMI alarm \"NVPM\\AE2700A05\\DATA_COMM_ALM\" to clear from the HMI Screen as intended. Data change was executed per Deployment Plan, no other changes were made. The toggling of tag AE2700A05.Data_Flt.Alarm was captured by the Factory Talk Asset Center (FTAC) audit log. \n",
      "----------------\n",
      "  Changed Data Bit Value of Tag [ \\OP.UDT_User.BOOL_MachineMode[0] ] to [ 0 ]\n",
      "i =  15\n",
      "i =  16\n",
      "i =  17\n",
      "i =  18\n",
      "i =  19\n",
      "i =  20\n",
      "i =  21\n",
      "i =  22\n",
      "i =  23\n",
      "i =  24\n",
      "i =  25\n",
      "i =  26\n",
      "i =  27\n",
      "i =  28\n",
      "i =  29\n",
      "i =  30\n",
      "i =  31\n",
      "i =  32\n",
      "i =  33\n",
      "i =  34\n",
      "i =  35\n",
      "i =  36\n",
      "i =  37\n",
      "i =  38\n",
      "i =  39\n",
      "i =  40\n",
      "i =  41\n",
      "i =  42\n",
      "i =  43\n",
      "i =  44\n",
      "i =  45\n",
      "i =  46\n",
      "i =  47\n",
      "i =  48\n",
      "i =  49\n",
      "i =  50\n",
      "i =  51\n",
      "i =  52\n",
      "i =  53\n",
      "i =  54\n",
      "i =  55\n",
      "i =  56\n",
      "i =  57\n",
      "i =  58\n",
      "i =  59\n",
      "i =  60\n",
      "i =  61\n",
      "i =  62\n",
      "i =  63\n",
      "i =  64\n",
      "i =  65\n",
      "i =  66\n",
      "i =  67\n",
      "i =  68\n",
      "i =  69\n",
      "i =  70\n",
      "i =  71\n",
      "i =  72\n",
      "i =  73\n",
      "i =  74\n",
      "i =  75\n",
      "i =  76\n",
      "i =  77\n",
      "i =  78\n",
      "i =  79\n",
      "i =  80\n",
      "i =  81\n",
      "i =  82\n",
      "i =  83\n",
      "i =  84\n",
      "i =  85\n",
      "i =  86\n",
      "i =  87\n",
      "i =  88\n",
      "i =  89\n",
      "i =  90\n",
      "i =  91\n",
      "i =  92\n",
      "i =  93\n",
      "i =  94\n",
      "i =  95\n",
      "i =  96\n",
      "i =  97\n",
      "i =  98\n",
      "i =  99\n",
      "i =  100\n",
      "i =  101\n",
      "i =  102\n",
      "i =  103\n",
      "i =  104\n",
      "i =  105\n",
      "i =  106\n",
      "i =  107\n",
      "i =  108\n",
      "i =  109\n",
      "i =  110\n"
     ]
    }
   ],
   "source": [
    "# compare the two dataFrames based on the \"Notes\" string\n",
    "for i in range(nrows_PLC_ServiceNow):\n",
    "#for i in range(6, 10):\n",
    "    row_PLC_ServiceNow = dataFrame1.iloc[i, :]\n",
    "    print('i = ', i)\n",
    "    #print(row_PLC_ServiceNow)\n",
    "    if(pd.isna(row_PLC_ServiceNow['Notes'])):\n",
    "        row_PLC_ServiceNow['Notes'] = '' # force NaN to empty string\n",
    "    \n",
    "    max_score = -100.0\n",
    "    max_j_idx = 0\n",
    "    for j in range(nrows_PLC_AuditTrail):        \n",
    "        row_PLC_AuditTrail = dataFrame2.iloc[j, :]\n",
    "        #print('j = ', j)\n",
    "        #print(row_PLC_AuditTrail)\n",
    "        \n",
    "        # average the two timestamps in AuditTrail\n",
    "        #if i == 6 and j == 53:\n",
    "        #    print(row_PLC_ServiceNow)\n",
    "        #    print(row_PLC_AuditTrail)\n",
    "        \n",
    "        #similarityScore_df = embeddings_similarity([row_PLC_ServiceNow['Notes'], row_PLC_AuditTrail['Notes']])\n",
    "        #similarityScore = similarityScore_df['similarity'][0]\n",
    "        \n",
    "        #similarityScore = doc_similarity(row_PLC_ServiceNow['Notes'], row_PLC_AuditTrail['Notes'])\n",
    "        \n",
    "        [similarityScore01,  similarityScore02]= sentence_similarity_ziyou(row_PLC_ServiceNow['Notes'], row_PLC_AuditTrail['Notes'])\n",
    "        if max_score < similarityScore01:\n",
    "            max_score = similarityScore01\n",
    "            max_j_idx = j            \n",
    "                \n",
    "        '''\n",
    "        if match == 1: # and i == 6 and j == 53:\n",
    "            print('ServiceNow record:', i)\n",
    "            print(df_PLC_ServiceNow['Change Implementer'][i], '\\t', df_PLC_ServiceNow['Deployment Actual Start Date'][i], '\\t', df_PLC_ServiceNow['Deployment Actual End Date'][i])\n",
    "            print('AuditTrail record:', j)\n",
    "            data_field = df_PLC_AuditTrail['Occurred'][j]\n",
    "            print(df_PLC_AuditTrail['Username'][j], '\\t', data_field.strftime('%Y-%m-%d'), '\\t', df_PLC_AuditTrail['Time'][j])\n",
    "            print('match.')\n",
    "            print('----------------------------------------------------------')\n",
    "        '''\n",
    "    if(max_score > 0.7): # ignore those max_scores that are not big enough\n",
    "        row_PLC_AuditTrail = dataFrame2.iloc[max_j_idx, :]    \n",
    "        print('i = ', i, 'max_j_idx = ', max_j_idx, 'max_score = ', max_score, 'matching sentences are:', row_PLC_ServiceNow['Notes'], '\\n----------------\\n', row_PLC_AuditTrail['Notes'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07013e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
